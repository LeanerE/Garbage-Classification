{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea6b68b",
   "metadata": {},
   "source": [
    "## Dataset Splitting Function\n",
    "Define function to split dataset into training, validation, and test sets (currently commented out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8245f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['ABSL_LOG_LEVEL'] = 'FATAL'\n",
    "\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "base_dir = '../data/garbage-dataset'\n",
    "classes = os.listdir(base_dir)\n",
    "train_dir = '../data/garbage-split/train'\n",
    "test_dir = '../data/garbage-split/test'\n",
    "val_dir = '../data/garbage-split/val'\n",
    "\n",
    "def split_dataset():\n",
    "    class_names = os.listdir(base_dir)\n",
    "    for class_name in class_names:\n",
    "        imgs = os.listdir(os.path.join(base_dir, class_name))\n",
    "        train_imgs, temp_imgs = train_test_split(imgs, test_size=0.2, random_state=42)\n",
    "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.25, random_state=42)\n",
    "        for split, split_imgs in zip([train_dir, val_dir, test_dir], [train_imgs, val_imgs, test_imgs]):\n",
    "            os.makedirs(os.path.join(split, class_name), exist_ok=True)\n",
    "            for img in split_imgs:\n",
    "                src = os.path.join(base_dir, class_name, img)\n",
    "                dst = os.path.join(split, class_name, img)\n",
    "                shutil.copyfile(src, dst)\n",
    "\n",
    "# split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4044eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 993 images belonging to 10 classes.\n",
      "\n",
      "=== ResNet50 Model Evaluation ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric-u/miniconda3/envs/tf216/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753898735.955687   60580 service.cc:145] XLA service 0x7af524002b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753898735.955796   60580 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti with Max-Q Design, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/32\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753898740.922593   60580 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 213ms/step\n",
      "Total Images: 993\n",
      "Correct Predictions: 965\n",
      "Wrong Predictions: 28\n",
      "Overall Accuracy: 97.18%\n",
      "\n",
      "Per-class results:\n",
      "  battery              Correct: 48   Wrong: 0    Accuracy: 100.00%\n",
      "  biological           Correct: 47   Wrong: 3    Accuracy: 94.00%\n",
      "  cardboard            Correct: 87   Wrong: 5    Accuracy: 94.57%\n",
      "  clothes              Correct: 262  Wrong: 5    Accuracy: 98.13%\n",
      "  glass                Correct: 150  Wrong: 4    Accuracy: 97.40%\n",
      "  metal                Correct: 48   Wrong: 3    Accuracy: 94.12%\n",
      "  paper                Correct: 82   Wrong: 2    Accuracy: 97.62%\n",
      "  plastic              Correct: 97   Wrong: 3    Accuracy: 97.00%\n",
      "  shoes                Correct: 98   Wrong: 1    Accuracy: 98.99%\n",
      "  trash                Correct: 46   Wrong: 2    Accuracy: 95.83%\n",
      "Found 993 images belonging to 10 classes.\n",
      "\n",
      "=== Custom CNN Model Evaluation ===\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 210ms/step\n",
      "Total Images: 993\n",
      "Correct Predictions: 876\n",
      "Wrong Predictions: 117\n",
      "Overall Accuracy: 88.22%\n",
      "\n",
      "Per-class results:\n",
      "  battery              Correct: 43   Wrong: 5    Accuracy: 89.58%\n",
      "  biological           Correct: 39   Wrong: 11   Accuracy: 78.00%\n",
      "  cardboard            Correct: 78   Wrong: 14   Accuracy: 84.78%\n",
      "  clothes              Correct: 245  Wrong: 22   Accuracy: 91.76%\n",
      "  glass                Correct: 141  Wrong: 13   Accuracy: 91.56%\n",
      "  metal                Correct: 43   Wrong: 8    Accuracy: 84.31%\n",
      "  paper                Correct: 74   Wrong: 10   Accuracy: 88.10%\n",
      "  plastic              Correct: 86   Wrong: 14   Accuracy: 86.00%\n",
      "  shoes                Correct: 82   Wrong: 17   Accuracy: 82.83%\n",
      "  trash                Correct: 45   Wrong: 3    Accuracy: 93.75%\n",
      "Found 993 images belonging to 10 classes.\n",
      "\n",
      "=== MobileNetV2 Model Evaluation ===\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 194ms/step\n",
      "Total Images: 993\n",
      "Correct Predictions: 956\n",
      "Wrong Predictions: 37\n",
      "Overall Accuracy: 96.27%\n",
      "\n",
      "Per-class results:\n",
      "  battery              Correct: 48   Wrong: 0    Accuracy: 100.00%\n",
      "  biological           Correct: 46   Wrong: 4    Accuracy: 92.00%\n",
      "  cardboard            Correct: 85   Wrong: 7    Accuracy: 92.39%\n",
      "  clothes              Correct: 263  Wrong: 4    Accuracy: 98.50%\n",
      "  glass                Correct: 146  Wrong: 8    Accuracy: 94.81%\n",
      "  metal                Correct: 49   Wrong: 2    Accuracy: 96.08%\n",
      "  paper                Correct: 82   Wrong: 2    Accuracy: 97.62%\n",
      "  plastic              Correct: 98   Wrong: 2    Accuracy: 98.00%\n",
      "  shoes                Correct: 96   Wrong: 3    Accuracy: 96.97%\n",
      "  trash                Correct: 43   Wrong: 5    Accuracy: 89.58%\n",
      "\n",
      "=== Model Accuracy Summary ===\n",
      "ResNet50 Accuracy:     97.18%\n",
      "Custom CNN Accuracy:   88.22%\n",
      "MobileNetV2 Accuracy:  96.27%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['ABSL_LOG_LEVEL'] = 'FATAL'\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from collections import defaultdict\n",
    "\n",
    "# Normalization values used by PyTorch pre-trained models\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def pytorch_normalize(img):\n",
    "    img = img / 255.0\n",
    "    return (img - mean) / std\n",
    "\n",
    "def evaluate_per_class(model, model_name, preprocessing_func):\n",
    "    test_dir = '../data/garbage-split/test'\n",
    "\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocessing_func)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    true_labels = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    class_names = list(class_indices.keys())\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "    print(f\"\\n=== {model_name} Model Evaluation ===\")\n",
    "    predictions = model.predict(test_generator, verbose=1)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Counters\n",
    "    correct = np.sum(predicted_labels == true_labels)\n",
    "    total = len(true_labels)\n",
    "    overall_acc = correct / total * 100\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "\n",
    "    for i in range(len(true_labels)):\n",
    "        true = true_labels[i]\n",
    "        pred = predicted_labels[i]\n",
    "        class_total[true] += 1\n",
    "        if true == pred:\n",
    "            class_correct[true] += 1\n",
    "\n",
    "    print(f\"Total Images: {total}\")\n",
    "    print(f\"Correct Predictions: {correct}\")\n",
    "    print(f\"Wrong Predictions: {total - correct}\")\n",
    "    print(f\"Overall Accuracy: {overall_acc:.2f}%\")\n",
    "\n",
    "    print(\"\\nPer-class results:\")\n",
    "    for class_id in range(len(class_names)):\n",
    "        total_cls = class_total[class_id]\n",
    "        correct_cls = class_correct[class_id]\n",
    "        wrong_cls = total_cls - correct_cls\n",
    "        acc = (correct_cls / total_cls * 100) if total_cls > 0 else 0.0\n",
    "        print(f\"  {inv_class_indices[class_id]:<20} Correct: {correct_cls:<3}  Wrong: {wrong_cls:<3}  Accuracy: {acc:.2f}%\")\n",
    "        \n",
    "    return overall_acc\n",
    "\n",
    "# Load models\n",
    "resnet50_model = load_model(\"saved_models/best_resnet50.keras\")\n",
    "custom_cnn_model = load_model(\"saved_models/best_custom_cnn.keras\")\n",
    "mobilenetv2_model = load_model(\"saved_models/best_mobilenetv2.keras\")\n",
    "\n",
    "# Evaluate all models\n",
    "resnet50_acc = evaluate_per_class(resnet50_model, \"ResNet50\", pytorch_normalize)\n",
    "custom_cnn_acc = evaluate_per_class(custom_cnn_model, \"Custom CNN\", pytorch_normalize)\n",
    "mobilenetv2_acc = evaluate_per_class(mobilenetv2_model, \"MobileNetV2\", pytorch_normalize)\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== Model Accuracy Summary ===\")\n",
    "print(f\"ResNet50 Accuracy:     {resnet50_acc:.2f}%\")\n",
    "print(f\"Custom CNN Accuracy:   {custom_cnn_acc:.2f}%\")\n",
    "print(f\"MobileNetV2 Accuracy:  {mobilenetv2_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf216",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
