{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51450c5e",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import all necessary libraries for deep learning, data processing, and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840af19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['ABSL_LOG_LEVEL'] = 'FATAL'\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1055ef8",
   "metadata": {},
   "source": [
    "## 2. Set Random Seeds\n",
    "Ensure reproducibility of experiments by setting consistent random seeds for all operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1bb7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ba203",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Augmentation\n",
    "Define image data generators with normalization, rotation, flipping, and other data augmentation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a996b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def pytorch_normalize(img):\n",
    "    img = img / 255.0\n",
    "    return (img - mean) / std\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=pytorch_normalize,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=[0.95, 1.05],\n",
    "    brightness_range=[0.85, 1.15],\n",
    "    horizontal_flip=True,\n",
    "    channel_shift_range=0.02,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=pytorch_normalize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4283a",
   "metadata": {},
   "source": [
    "## 4. Create Data Generators\n",
    "Create data generators for training, validation, and test sets, and display dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe13730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15806 images belonging to 10 classes.\n",
      "Found 2963 images belonging to 10 classes.\n",
      "Found 993 images belonging to 10 classes.\n",
      "Number of training samples: 15806, Steps per epoch: 494\n",
      "Number of validation samples: 2963, Validation steps: 93\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../data/garbage-dataset'\n",
    "classes = os.listdir(base_dir)\n",
    "train_dir = '../data/garbage-split/train'\n",
    "test_dir = '../data/garbage-split/test'\n",
    "val_dir = '../data/garbage-split/val'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=True, seed=SEED\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir, target_size=(224, 224), batch_size=32, class_mode='categorical',shuffle=False\n",
    ")\n",
    "\n",
    "train_steps = int(np.ceil(train_generator.samples / 32))\n",
    "val_steps = int(np.ceil(val_generator.samples / 32))\n",
    "\n",
    "print(f\"Number of training samples: {train_generator.samples}, Steps per epoch: {train_steps}\")\n",
    "print(f\"Number of validation samples: {val_generator.samples}, Validation steps: {val_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581319d1",
   "metadata": {},
   "source": [
    "## 5. Build ResNet50 Model\n",
    "Use pre-trained ResNet50 as base model and add custom classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98949cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "base_model.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecce521",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "Train the model using callbacks including early stopping, learning rate reduction, and model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9628985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric-u/miniconda3/envs/tf216/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753894099.637029   46361 service.cc:145] XLA service 0x7c8bf809f4b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753894099.637103   46361 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti with Max-Q Design, Compute Capability 7.5\n",
      "I0000 00:00:1753894131.088801   46361 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.4278 - loss: 1.8480\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78299, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 466ms/step - accuracy: 0.4282 - loss: 1.8467 - val_accuracy: 0.7830 - val_loss: 0.6744 - learning_rate: 1.0000e-05\n",
      "Epoch 2/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.8342 - loss: 0.5152\n",
      "Epoch 2: val_accuracy improved from 0.78299 to 0.92103, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 384ms/step - accuracy: 0.8343 - loss: 0.5150 - val_accuracy: 0.9210 - val_loss: 0.2480 - learning_rate: 1.0000e-05\n",
      "Epoch 3/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - accuracy: 0.9003 - loss: 0.3117\n",
      "Epoch 3: val_accuracy improved from 0.92103 to 0.94060, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 505ms/step - accuracy: 0.9003 - loss: 0.3116 - val_accuracy: 0.9406 - val_loss: 0.1995 - learning_rate: 1.0000e-05\n",
      "Epoch 4/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.9266 - loss: 0.2267\n",
      "Epoch 4: val_accuracy improved from 0.94060 to 0.94533, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 409ms/step - accuracy: 0.9266 - loss: 0.2267 - val_accuracy: 0.9453 - val_loss: 0.1745 - learning_rate: 1.0000e-05\n",
      "Epoch 5/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.9435 - loss: 0.1713\n",
      "Epoch 5: val_accuracy improved from 0.94533 to 0.95241, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 392ms/step - accuracy: 0.9435 - loss: 0.1713 - val_accuracy: 0.9524 - val_loss: 0.1557 - learning_rate: 1.0000e-05\n",
      "Epoch 6/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.9543 - loss: 0.1385\n",
      "Epoch 6: val_accuracy improved from 0.95241 to 0.95646, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 398ms/step - accuracy: 0.9544 - loss: 0.1385 - val_accuracy: 0.9565 - val_loss: 0.1445 - learning_rate: 1.0000e-05\n",
      "Epoch 7/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.9695 - loss: 0.1047\n",
      "Epoch 7: val_accuracy improved from 0.95646 to 0.96018, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 388ms/step - accuracy: 0.9695 - loss: 0.1047 - val_accuracy: 0.9602 - val_loss: 0.1367 - learning_rate: 1.0000e-05\n",
      "Epoch 8/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.9712 - loss: 0.0893\n",
      "Epoch 8: val_accuracy did not improve from 0.96018\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 393ms/step - accuracy: 0.9712 - loss: 0.0893 - val_accuracy: 0.9585 - val_loss: 0.1390 - learning_rate: 1.0000e-05\n",
      "Epoch 9/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.9789 - loss: 0.0686\n",
      "Epoch 9: val_accuracy did not improve from 0.96018\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 394ms/step - accuracy: 0.9789 - loss: 0.0686 - val_accuracy: 0.9595 - val_loss: 0.1369 - learning_rate: 1.0000e-05\n",
      "Epoch 10/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.9822 - loss: 0.0579\n",
      "Epoch 10: val_accuracy improved from 0.96018 to 0.96051, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 392ms/step - accuracy: 0.9822 - loss: 0.0579 - val_accuracy: 0.9605 - val_loss: 0.1305 - learning_rate: 1.0000e-05\n",
      "Epoch 11/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.9867 - loss: 0.0418\n",
      "Epoch 11: val_accuracy improved from 0.96051 to 0.96085, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 396ms/step - accuracy: 0.9867 - loss: 0.0418 - val_accuracy: 0.9609 - val_loss: 0.1281 - learning_rate: 1.0000e-05\n",
      "Epoch 12/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.9888 - loss: 0.0372\n",
      "Epoch 12: val_accuracy improved from 0.96085 to 0.96288, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 393ms/step - accuracy: 0.9888 - loss: 0.0372 - val_accuracy: 0.9629 - val_loss: 0.1279 - learning_rate: 1.0000e-05\n",
      "Epoch 13/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.9906 - loss: 0.0293\n",
      "Epoch 13: val_accuracy did not improve from 0.96288\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 394ms/step - accuracy: 0.9906 - loss: 0.0293 - val_accuracy: 0.9622 - val_loss: 0.1359 - learning_rate: 1.0000e-05\n",
      "Epoch 14/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.9921 - loss: 0.0246\n",
      "Epoch 14: val_accuracy improved from 0.96288 to 0.96625, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 393ms/step - accuracy: 0.9920 - loss: 0.0246 - val_accuracy: 0.9663 - val_loss: 0.1337 - learning_rate: 1.0000e-05\n",
      "Epoch 15/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.9927 - loss: 0.0214\n",
      "Epoch 15: val_accuracy did not improve from 0.96625\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 394ms/step - accuracy: 0.9927 - loss: 0.0214 - val_accuracy: 0.9629 - val_loss: 0.1438 - learning_rate: 1.0000e-05\n",
      "Epoch 16/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.9923 - loss: 0.0247\n",
      "Epoch 16: val_accuracy did not improve from 0.96625\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 388ms/step - accuracy: 0.9923 - loss: 0.0247 - val_accuracy: 0.9609 - val_loss: 0.1473 - learning_rate: 1.0000e-05\n",
      "Epoch 17/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.9959 - loss: 0.0175\n",
      "Epoch 17: val_accuracy did not improve from 0.96625\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 400ms/step - accuracy: 0.9959 - loss: 0.0175 - val_accuracy: 0.9605 - val_loss: 0.1510 - learning_rate: 1.0000e-05\n",
      "Epoch 18/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.9956 - loss: 0.0157\n",
      "Epoch 18: val_accuracy did not improve from 0.96625\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 393ms/step - accuracy: 0.9956 - loss: 0.0157 - val_accuracy: 0.9652 - val_loss: 0.1402 - learning_rate: 5.0000e-06\n",
      "Epoch 19/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.9959 - loss: 0.0143\n",
      "Epoch 19: val_accuracy did not improve from 0.96625\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 403ms/step - accuracy: 0.9959 - loss: 0.0143 - val_accuracy: 0.9646 - val_loss: 0.1435 - learning_rate: 5.0000e-06\n",
      "Epoch 20/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.9969 - loss: 0.0113\n",
      "Epoch 20: val_accuracy did not improve from 0.96625\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 405ms/step - accuracy: 0.9969 - loss: 0.0113 - val_accuracy: 0.9652 - val_loss: 0.1418 - learning_rate: 5.0000e-06\n",
      "Epoch 21/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.9978 - loss: 0.0087\n",
      "Epoch 21: val_accuracy did not improve from 0.96625\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 383ms/step - accuracy: 0.9978 - loss: 0.0087 - val_accuracy: 0.9659 - val_loss: 0.1395 - learning_rate: 2.5000e-06\n",
      "Epoch 22/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.9981 - loss: 0.0083\n",
      "Epoch 22: val_accuracy did not improve from 0.96625\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 371ms/step - accuracy: 0.9981 - loss: 0.0083 - val_accuracy: 0.9636 - val_loss: 0.1401 - learning_rate: 2.5000e-06\n",
      "Epoch 23/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.9978 - loss: 0.0081\n",
      "Epoch 23: val_accuracy did not improve from 0.96625\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 396ms/step - accuracy: 0.9978 - loss: 0.0081 - val_accuracy: 0.9659 - val_loss: 0.1400 - learning_rate: 2.5000e-06\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('saved_models/best_resnet50.keras',monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=9, restore_best_weights=True, min_delta=0.001, verbose=1)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=40,\n",
    "    callbacks=[checkpoint, early_stop, lr_reduce],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save('saved_models/resnet50_final.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8b7e9",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "Evaluate model performance on test set and generate detailed classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43f77f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery       0.96      1.00      0.98        48\n",
      "  biological       1.00      0.94      0.97        50\n",
      "   cardboard       0.98      0.95      0.96        92\n",
      "     clothes       0.99      0.98      0.99       267\n",
      "       glass       0.98      0.97      0.98       154\n",
      "       metal       0.98      0.94      0.96        51\n",
      "       paper       0.90      0.98      0.94        84\n",
      "     plastic       0.98      0.97      0.97       100\n",
      "       shoes       0.95      0.99      0.97        99\n",
      "       trash       0.96      0.96      0.96        48\n",
      "\n",
      "    accuracy                           0.97       993\n",
      "   macro avg       0.97      0.97      0.97       993\n",
      "weighted avg       0.97      0.97      0.97       993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=list(test_generator.class_indices.keys())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf216",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
