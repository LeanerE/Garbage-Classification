{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51450c5e",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import all necessary libraries for deep learning, data processing, and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "840af19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['ABSL_LOG_LEVEL'] = 'FATAL'\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1055ef8",
   "metadata": {},
   "source": [
    "## 2. Set Random Seeds\n",
    "Ensure reproducibility of experiments by setting consistent random seeds for all operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a1bb7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ba203",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Augmentation\n",
    "Define image data generators with normalization, rotation, flipping, and other data augmentation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9a996b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def pytorch_normalize(img):\n",
    "    img = img / 255.0\n",
    "    return (img - mean) / std\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=pytorch_normalize,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=[0.95, 1.05],\n",
    "    brightness_range=[0.85, 1.15],\n",
    "    horizontal_flip=True,\n",
    "    channel_shift_range=0.02,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=pytorch_normalize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4283a",
   "metadata": {},
   "source": [
    "## 4. Create Data Generators\n",
    "Create data generators for training, validation, and test sets, and display dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffe13730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15806 images belonging to 10 classes.\n",
      "Found 2963 images belonging to 10 classes.\n",
      "Found 993 images belonging to 10 classes.\n",
      "Number of training samples: 15806, Steps per epoch: 494\n",
      "Number of validation samples: 2963, Validation steps: 93\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../data/garbage-dataset'\n",
    "classes = os.listdir(base_dir)\n",
    "train_dir = '../data/garbage-split/train'\n",
    "test_dir = '../data/garbage-split/test'\n",
    "val_dir = '../data/garbage-split/val'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=True, seed=SEED\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir, target_size=(224, 224), batch_size=32, class_mode='categorical',shuffle=False\n",
    ")\n",
    "\n",
    "train_steps = int(np.ceil(train_generator.samples / 32))\n",
    "val_steps = int(np.ceil(val_generator.samples / 32))\n",
    "\n",
    "print(f\"Number of training samples: {train_generator.samples}, Steps per epoch: {train_steps}\")\n",
    "print(f\"Number of validation samples: {val_generator.samples}, Validation steps: {val_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581319d1",
   "metadata": {},
   "source": [
    "## 5. Build ResNet50 Model\n",
    "Use pre-trained ResNet50 as base model and add custom classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98949cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "base_model.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecce521",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "Train the model using callbacks including early stopping, learning rate reduction, and model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9628985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric-u/miniconda3/envs/tf216/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.4278 - loss: 1.8482\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78333, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 436ms/step - accuracy: 0.4282 - loss: 1.8469 - val_accuracy: 0.7833 - val_loss: 0.6730 - learning_rate: 1.0000e-05\n",
      "Epoch 2/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8350 - loss: 0.5154\n",
      "Epoch 2: val_accuracy improved from 0.78333 to 0.92305, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 391ms/step - accuracy: 0.8351 - loss: 0.5153 - val_accuracy: 0.9231 - val_loss: 0.2477 - learning_rate: 1.0000e-05\n",
      "Epoch 3/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.9014 - loss: 0.3115\n",
      "Epoch 3: val_accuracy improved from 0.92305 to 0.94026, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 402ms/step - accuracy: 0.9014 - loss: 0.3114 - val_accuracy: 0.9403 - val_loss: 0.1992 - learning_rate: 1.0000e-05\n",
      "Epoch 4/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.9270 - loss: 0.2269\n",
      "Epoch 4: val_accuracy improved from 0.94026 to 0.94566, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 383ms/step - accuracy: 0.9270 - loss: 0.2269 - val_accuracy: 0.9457 - val_loss: 0.1731 - learning_rate: 1.0000e-05\n",
      "Epoch 5/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.9451 - loss: 0.1705\n",
      "Epoch 5: val_accuracy improved from 0.94566 to 0.95444, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 382ms/step - accuracy: 0.9451 - loss: 0.1705 - val_accuracy: 0.9544 - val_loss: 0.1562 - learning_rate: 1.0000e-05\n",
      "Epoch 6/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.9544 - loss: 0.1387\n",
      "Epoch 6: val_accuracy improved from 0.95444 to 0.95646, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 381ms/step - accuracy: 0.9544 - loss: 0.1387 - val_accuracy: 0.9565 - val_loss: 0.1452 - learning_rate: 1.0000e-05\n",
      "Epoch 7/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.9686 - loss: 0.1054\n",
      "Epoch 7: val_accuracy improved from 0.95646 to 0.95883, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 391ms/step - accuracy: 0.9686 - loss: 0.1054 - val_accuracy: 0.9588 - val_loss: 0.1372 - learning_rate: 1.0000e-05\n",
      "Epoch 8/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.9721 - loss: 0.0886\n",
      "Epoch 8: val_accuracy did not improve from 0.95883\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 392ms/step - accuracy: 0.9721 - loss: 0.0886 - val_accuracy: 0.9585 - val_loss: 0.1393 - learning_rate: 1.0000e-05\n",
      "Epoch 9/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.9793 - loss: 0.0684\n",
      "Epoch 9: val_accuracy improved from 0.95883 to 0.96153, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 377ms/step - accuracy: 0.9793 - loss: 0.0684 - val_accuracy: 0.9615 - val_loss: 0.1360 - learning_rate: 1.0000e-05\n",
      "Epoch 10/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.9821 - loss: 0.0584\n",
      "Epoch 10: val_accuracy improved from 0.96153 to 0.96186, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 382ms/step - accuracy: 0.9821 - loss: 0.0583 - val_accuracy: 0.9619 - val_loss: 0.1311 - learning_rate: 1.0000e-05\n",
      "Epoch 11/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9863 - loss: 0.0423\n",
      "Epoch 11: val_accuracy improved from 0.96186 to 0.96355, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 382ms/step - accuracy: 0.9863 - loss: 0.0423 - val_accuracy: 0.9636 - val_loss: 0.1266 - learning_rate: 1.0000e-05\n",
      "Epoch 12/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.9882 - loss: 0.0373\n",
      "Epoch 12: val_accuracy did not improve from 0.96355\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 395ms/step - accuracy: 0.9882 - loss: 0.0373 - val_accuracy: 0.9629 - val_loss: 0.1281 - learning_rate: 1.0000e-05\n",
      "Epoch 13/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.9914 - loss: 0.0287\n",
      "Epoch 13: val_accuracy did not improve from 0.96355\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 397ms/step - accuracy: 0.9914 - loss: 0.0287 - val_accuracy: 0.9636 - val_loss: 0.1354 - learning_rate: 1.0000e-05\n",
      "Epoch 14/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.9925 - loss: 0.0236\n",
      "Epoch 14: val_accuracy improved from 0.96355 to 0.96558, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 382ms/step - accuracy: 0.9925 - loss: 0.0236 - val_accuracy: 0.9656 - val_loss: 0.1383 - learning_rate: 1.0000e-05\n",
      "Epoch 15/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.9933 - loss: 0.0214\n",
      "Epoch 15: val_accuracy did not improve from 0.96558\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 392ms/step - accuracy: 0.9933 - loss: 0.0214 - val_accuracy: 0.9629 - val_loss: 0.1472 - learning_rate: 1.0000e-05\n",
      "Epoch 16/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9920 - loss: 0.0244\n",
      "Epoch 16: val_accuracy did not improve from 0.96558\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 379ms/step - accuracy: 0.9920 - loss: 0.0244 - val_accuracy: 0.9636 - val_loss: 0.1503 - learning_rate: 1.0000e-05\n",
      "Epoch 17/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.9951 - loss: 0.0179\n",
      "Epoch 17: val_accuracy did not improve from 0.96558\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 384ms/step - accuracy: 0.9951 - loss: 0.0179 - val_accuracy: 0.9632 - val_loss: 0.1501 - learning_rate: 1.0000e-05\n",
      "Epoch 18/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.9957 - loss: 0.0161\n",
      "Epoch 18: val_accuracy did not improve from 0.96558\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 398ms/step - accuracy: 0.9957 - loss: 0.0161 - val_accuracy: 0.9656 - val_loss: 0.1426 - learning_rate: 5.0000e-06\n",
      "Epoch 19/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.9959 - loss: 0.0159\n",
      "Epoch 19: val_accuracy did not improve from 0.96558\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 376ms/step - accuracy: 0.9959 - loss: 0.0159 - val_accuracy: 0.9639 - val_loss: 0.1452 - learning_rate: 5.0000e-06\n",
      "Epoch 20/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.9969 - loss: 0.0111\n",
      "Epoch 20: val_accuracy did not improve from 0.96558\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 396ms/step - accuracy: 0.9969 - loss: 0.0111 - val_accuracy: 0.9632 - val_loss: 0.1480 - learning_rate: 5.0000e-06\n",
      "Epoch 21/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.9976 - loss: 0.0086\n",
      "Epoch 21: val_accuracy improved from 0.96558 to 0.96726, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 401ms/step - accuracy: 0.9976 - loss: 0.0086 - val_accuracy: 0.9673 - val_loss: 0.1430 - learning_rate: 2.5000e-06\n",
      "Epoch 22/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.9976 - loss: 0.0087\n",
      "Epoch 22: val_accuracy did not improve from 0.96726\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 382ms/step - accuracy: 0.9976 - loss: 0.0087 - val_accuracy: 0.9649 - val_loss: 0.1434 - learning_rate: 2.5000e-06\n",
      "Epoch 23/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.9977 - loss: 0.0083\n",
      "Epoch 23: val_accuracy did not improve from 0.96726\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 381ms/step - accuracy: 0.9977 - loss: 0.0083 - val_accuracy: 0.9652 - val_loss: 0.1429 - learning_rate: 2.5000e-06\n",
      "Epoch 24/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.9982 - loss: 0.0066\n",
      "Epoch 24: val_accuracy did not improve from 0.96726\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 385ms/step - accuracy: 0.9982 - loss: 0.0066 - val_accuracy: 0.9669 - val_loss: 0.1448 - learning_rate: 2.5000e-06\n",
      "Epoch 25/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.9988 - loss: 0.0061\n",
      "Epoch 25: val_accuracy did not improve from 0.96726\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 378ms/step - accuracy: 0.9988 - loss: 0.0061 - val_accuracy: 0.9663 - val_loss: 0.1440 - learning_rate: 1.2500e-06\n",
      "Epoch 26/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.9980 - loss: 0.0066\n",
      "Epoch 26: val_accuracy did not improve from 0.96726\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 382ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.9666 - val_loss: 0.1459 - learning_rate: 1.2500e-06\n",
      "Epoch 27/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.9981 - loss: 0.0070\n",
      "Epoch 27: val_accuracy did not improve from 0.96726\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 383ms/step - accuracy: 0.9981 - loss: 0.0070 - val_accuracy: 0.9673 - val_loss: 0.1463 - learning_rate: 1.2500e-06\n",
      "Epoch 28/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.9983 - loss: 0.0074\n",
      "Epoch 28: val_accuracy did not improve from 0.96726\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 384ms/step - accuracy: 0.9983 - loss: 0.0074 - val_accuracy: 0.9669 - val_loss: 0.1457 - learning_rate: 1.0000e-06\n",
      "Epoch 29/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.9978 - loss: 0.0075\n",
      "Epoch 29: val_accuracy improved from 0.96726 to 0.96794, saving model to saved_models/best_resnet50.keras\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 388ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9679 - val_loss: 0.1431 - learning_rate: 1.0000e-06\n",
      "Epoch 30/40\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.9985 - loss: 0.0059\n",
      "Epoch 30: val_accuracy did not improve from 0.96794\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 404ms/step - accuracy: 0.9985 - loss: 0.0059 - val_accuracy: 0.9666 - val_loss: 0.1456 - learning_rate: 1.0000e-06\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('saved_models/best_resnet50.keras',monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=9, restore_best_weights=True, min_delta=0.001, verbose=1)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=40,\n",
    "    callbacks=[checkpoint, early_stop, lr_reduce],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save('saved_models/resnet50_final.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8b7e9",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "Evaluate model performance on test set and generate detailed classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43f77f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 190ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery       0.96      1.00      0.98        48\n",
      "  biological       1.00      0.92      0.96        50\n",
      "   cardboard       0.99      0.97      0.98        92\n",
      "     clothes       0.99      0.99      0.99       267\n",
      "       glass       0.98      0.97      0.97       154\n",
      "       metal       0.94      0.92      0.93        51\n",
      "       paper       0.93      0.98      0.95        84\n",
      "     plastic       0.98      0.97      0.97       100\n",
      "       shoes       0.95      0.99      0.97        99\n",
      "       trash       0.94      0.98      0.96        48\n",
      "\n",
      "    accuracy                           0.97       993\n",
      "   macro avg       0.97      0.97      0.97       993\n",
      "weighted avg       0.97      0.97      0.97       993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=list(test_generator.class_indices.keys())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf216",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
