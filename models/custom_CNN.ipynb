{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b2fb9d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Global Settings\n",
    "Import required Python libraries, set random seed for reproducibility, and count dataset category information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b248ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['battery', 'biological', 'cardboard', 'clothes', 'glass', 'metal', 'paper', 'plastic', 'shoes', 'trash']\n",
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['ABSL_LOG_LEVEL'] = 'FATAL'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "base_dir = '../data/garbage-dataset'\n",
    "classes = os.listdir(base_dir)\n",
    "train_dir = '../data/garbage-split/train'\n",
    "test_dir = '../data/garbage-split/test'\n",
    "val_dir = '../data/garbage-split/val'\n",
    "\n",
    "class_names = sorted(classes)\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e7eda",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation\n",
    "Apply augmentation to training data and rescaling to validation data using `ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac121d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def pytorch_normalize(img):\n",
    "    img = img / 255.0\n",
    "    return (img - mean) / std\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=pytorch_normalize,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=[0.95, 1.05],\n",
    "    brightness_range=[0.85, 1.15],\n",
    "    horizontal_flip=True,\n",
    "    channel_shift_range=0.02,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=pytorch_normalize,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4330f64",
   "metadata": {},
   "source": [
    "## 3. Data Generators\n",
    "Load images from folders using `flow_from_directory` for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9946934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15806 images belonging to 10 classes.\n",
      "Found 2963 images belonging to 10 classes.\n",
      "Found 993 images belonging to 10 classes.\n",
      "Number of training samples: 15806, Steps per epoch: 988\n",
      "Number of validation samples: 2963, Validation steps: 186\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16, \n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_steps = int(np.ceil(train_generator.samples / 16))\n",
    "val_steps = int(np.ceil(val_generator.samples / 16))\n",
    "\n",
    "print(f\"Number of training samples: {train_generator.samples}, Steps per epoch: {train_steps}\")\n",
    "print(f\"Number of validation samples: {val_generator.samples}, Validation steps: {val_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee43506a",
   "metadata": {},
   "source": [
    "## 4. Compute Class Weights\n",
    "Handle class imbalance by assigning weights to different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4295cd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 2.0935099337748344, 1: 1.9831869510664994, 2: 1.0826027397260274, 3: 0.3709457873738559, 4: 0.6456699346405229, 5: 1.9370098039215686, 6: 1.1760416666666667, 7: 0.9959672337744171, 8: 0.9997469955724225, 9: 2.0879788639365917}\n"
     ]
    }
   ],
   "source": [
    "y_train = train_generator.classes\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print('Class weights:', class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e4551",
   "metadata": {},
   "source": [
    "## 5. Adjust Specific Class Weights\n",
    "Increase weights for metal and trash classes to improve their recognition accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa635061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 2.0935099337748344, 1: 3.966373902132999, 2: 1.0826027397260274, 3: 0.3709457873738559, 4: 1.0976388888888888, 5: 2.9055147058823527, 6: 1.1760416666666667, 7: 1.1951606805293005, 8: 1.4996204933586337, 9: 5.219947159841479}\n"
     ]
    }
   ],
   "source": [
    "class_weight_dict[1] *= 2.0  # biological\n",
    "class_weight_dict[4] *= 1.7  # glass\n",
    "class_weight_dict[5] *= 1.5 # metal\n",
    "class_weight_dict[7] *= 1.2 # plastic\n",
    "class_weight_dict[8] *= 1.5  # shoes\n",
    "class_weight_dict[9] *= 2.5  # trash\n",
    "print('Class weights:', class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d956c41",
   "metadata": {},
   "source": [
    "## 6. Build CNN Model\n",
    "\n",
    "Create a CNN with Conv-BatchNorm-Pool blocks and global average pooling for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a76c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(224, 224, 3)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd0697",
   "metadata": {},
   "source": [
    "## 7. Compile Model\n",
    "\n",
    "Compile the model with Adam optimizer and categorical cross-entropy loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b975642",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8391abff",
   "metadata": {},
   "source": [
    "## 8. Train Model\n",
    "\n",
    "Train the model with early stopping, checkpointing, and learning rate scheduling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1512fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753857784.173143    1248 service.cc:145] XLA service 0x7d6db001e860 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753857784.173235    1248 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti with Max-Q Design, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/988\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 83ms/step - accuracy: 0.0781 - loss: 3.8893  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753857806.701632    1248 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.2687 - loss: 2.7754\n",
      "Epoch 1: val_accuracy improved from -inf to 0.36011, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 217ms/step - accuracy: 0.2687 - loss: 2.7753 - val_accuracy: 0.3601 - val_loss: 1.8650 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.3724 - loss: 2.3556\n",
      "Epoch 2: val_accuracy improved from 0.36011 to 0.42288, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 183ms/step - accuracy: 0.3724 - loss: 2.3556 - val_accuracy: 0.4229 - val_loss: 1.6787 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.4284 - loss: 2.1320\n",
      "Epoch 3: val_accuracy did not improve from 0.42288\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 178ms/step - accuracy: 0.4284 - loss: 2.1321 - val_accuracy: 0.4225 - val_loss: 1.7378 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.4661 - loss: 2.0216\n",
      "Epoch 4: val_accuracy improved from 0.42288 to 0.45427, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 177ms/step - accuracy: 0.4661 - loss: 2.0215 - val_accuracy: 0.4543 - val_loss: 1.7454 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.4917 - loss: 1.9324\n",
      "Epoch 5: val_accuracy improved from 0.45427 to 0.52413, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 178ms/step - accuracy: 0.4918 - loss: 1.9323 - val_accuracy: 0.5241 - val_loss: 1.4262 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.5284 - loss: 1.8061\n",
      "Epoch 6: val_accuracy improved from 0.52413 to 0.55451, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 173ms/step - accuracy: 0.5284 - loss: 1.8061 - val_accuracy: 0.5545 - val_loss: 1.3335 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5472 - loss: 1.7253\n",
      "Epoch 7: val_accuracy did not improve from 0.55451\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 174ms/step - accuracy: 0.5472 - loss: 1.7253 - val_accuracy: 0.4850 - val_loss: 2.0477 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.5629 - loss: 1.6769\n",
      "Epoch 8: val_accuracy improved from 0.55451 to 0.62437, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 170ms/step - accuracy: 0.5629 - loss: 1.6769 - val_accuracy: 0.6244 - val_loss: 1.1598 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5956 - loss: 1.5705\n",
      "Epoch 9: val_accuracy did not improve from 0.62437\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.5956 - loss: 1.5705 - val_accuracy: 0.5309 - val_loss: 1.4369 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5975 - loss: 1.5267\n",
      "Epoch 10: val_accuracy improved from 0.62437 to 0.68275, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 173ms/step - accuracy: 0.5976 - loss: 1.5267 - val_accuracy: 0.6828 - val_loss: 0.9711 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.6251 - loss: 1.4421\n",
      "Epoch 11: val_accuracy improved from 0.68275 to 0.68444, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 172ms/step - accuracy: 0.6251 - loss: 1.4421 - val_accuracy: 0.6844 - val_loss: 1.0504 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.6433 - loss: 1.3529\n",
      "Epoch 12: val_accuracy improved from 0.68444 to 0.69592, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 170ms/step - accuracy: 0.6433 - loss: 1.3529 - val_accuracy: 0.6959 - val_loss: 0.9355 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.6627 - loss: 1.2984\n",
      "Epoch 13: val_accuracy did not improve from 0.69592\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 173ms/step - accuracy: 0.6627 - loss: 1.2984 - val_accuracy: 0.6949 - val_loss: 0.9442 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6817 - loss: 1.2328\n",
      "Epoch 14: val_accuracy improved from 0.69592 to 0.71650, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.6817 - loss: 1.2328 - val_accuracy: 0.7165 - val_loss: 0.8650 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6814 - loss: 1.2361\n",
      "Epoch 15: val_accuracy did not improve from 0.71650\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 169ms/step - accuracy: 0.6814 - loss: 1.2361 - val_accuracy: 0.6828 - val_loss: 1.0353 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7026 - loss: 1.1584\n",
      "Epoch 16: val_accuracy improved from 0.71650 to 0.73507, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.7026 - loss: 1.1584 - val_accuracy: 0.7351 - val_loss: 0.8348 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7167 - loss: 1.1068\n",
      "Epoch 17: val_accuracy improved from 0.73507 to 0.75532, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 173ms/step - accuracy: 0.7167 - loss: 1.1068 - val_accuracy: 0.7553 - val_loss: 0.8100 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7309 - loss: 1.0602\n",
      "Epoch 18: val_accuracy did not improve from 0.75532\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 173ms/step - accuracy: 0.7309 - loss: 1.0602 - val_accuracy: 0.7327 - val_loss: 0.8417 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7372 - loss: 1.0149\n",
      "Epoch 19: val_accuracy improved from 0.75532 to 0.77827, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 172ms/step - accuracy: 0.7372 - loss: 1.0149 - val_accuracy: 0.7783 - val_loss: 0.7028 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7544 - loss: 0.9776\n",
      "Epoch 20: val_accuracy did not improve from 0.77827\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 172ms/step - accuracy: 0.7544 - loss: 0.9776 - val_accuracy: 0.6952 - val_loss: 1.0167 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7552 - loss: 0.9417\n",
      "Epoch 21: val_accuracy did not improve from 0.77827\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 170ms/step - accuracy: 0.7552 - loss: 0.9417 - val_accuracy: 0.7719 - val_loss: 0.7905 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7739 - loss: 0.8825\n",
      "Epoch 22: val_accuracy improved from 0.77827 to 0.78265, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 173ms/step - accuracy: 0.7739 - loss: 0.8825 - val_accuracy: 0.7827 - val_loss: 0.7129 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7680 - loss: 0.8977\n",
      "Epoch 23: val_accuracy did not improve from 0.78265\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 173ms/step - accuracy: 0.7680 - loss: 0.8977 - val_accuracy: 0.7648 - val_loss: 0.7647 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7759 - loss: 0.8478\n",
      "Epoch 24: val_accuracy did not improve from 0.78265\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 172ms/step - accuracy: 0.7760 - loss: 0.8478 - val_accuracy: 0.7766 - val_loss: 0.7011 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7923 - loss: 0.8201\n",
      "Epoch 25: val_accuracy improved from 0.78265 to 0.78400, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 171ms/step - accuracy: 0.7923 - loss: 0.8201 - val_accuracy: 0.7840 - val_loss: 0.7463 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7935 - loss: 0.7966\n",
      "Epoch 26: val_accuracy did not improve from 0.78400\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 175ms/step - accuracy: 0.7935 - loss: 0.7966 - val_accuracy: 0.7800 - val_loss: 0.7563 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8079 - loss: 0.7232\n",
      "Epoch 27: val_accuracy improved from 0.78400 to 0.78569, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 170ms/step - accuracy: 0.8079 - loss: 0.7233 - val_accuracy: 0.7857 - val_loss: 0.7463 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8063 - loss: 0.7422\n",
      "Epoch 28: val_accuracy improved from 0.78569 to 0.79818, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 175ms/step - accuracy: 0.8063 - loss: 0.7422 - val_accuracy: 0.7982 - val_loss: 0.6887 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.8064 - loss: 0.7421\n",
      "Epoch 29: val_accuracy improved from 0.79818 to 0.81539, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.8064 - loss: 0.7421 - val_accuracy: 0.8154 - val_loss: 0.6340 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8190 - loss: 0.6926\n",
      "Epoch 30: val_accuracy did not improve from 0.81539\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.8190 - loss: 0.6926 - val_accuracy: 0.7948 - val_loss: 0.6723 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8214 - loss: 0.6738\n",
      "Epoch 31: val_accuracy did not improve from 0.81539\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 180ms/step - accuracy: 0.8214 - loss: 0.6739 - val_accuracy: 0.8080 - val_loss: 0.6279 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8235 - loss: 0.6591\n",
      "Epoch 32: val_accuracy did not improve from 0.81539\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 176ms/step - accuracy: 0.8235 - loss: 0.6591 - val_accuracy: 0.5899 - val_loss: 1.5896 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8198 - loss: 0.7065\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.81539\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 177ms/step - accuracy: 0.8198 - loss: 0.7065 - val_accuracy: 0.7874 - val_loss: 0.7695 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8514 - loss: 0.5595\n",
      "Epoch 34: val_accuracy improved from 0.81539 to 0.83058, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 175ms/step - accuracy: 0.8514 - loss: 0.5594 - val_accuracy: 0.8306 - val_loss: 0.5842 - learning_rate: 2.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8610 - loss: 0.5119\n",
      "Epoch 35: val_accuracy improved from 0.83058 to 0.83530, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 172ms/step - accuracy: 0.8610 - loss: 0.5119 - val_accuracy: 0.8353 - val_loss: 0.5783 - learning_rate: 2.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.8673 - loss: 0.4885\n",
      "Epoch 36: val_accuracy did not improve from 0.83530\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 172ms/step - accuracy: 0.8673 - loss: 0.4886 - val_accuracy: 0.8350 - val_loss: 0.5528 - learning_rate: 2.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8718 - loss: 0.4973\n",
      "Epoch 37: val_accuracy improved from 0.83530 to 0.83901, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.8719 - loss: 0.4973 - val_accuracy: 0.8390 - val_loss: 0.5725 - learning_rate: 2.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8808 - loss: 0.4573\n",
      "Epoch 38: val_accuracy did not improve from 0.83901\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.8808 - loss: 0.4573 - val_accuracy: 0.8323 - val_loss: 0.5878 - learning_rate: 2.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8800 - loss: 0.4571\n",
      "Epoch 39: val_accuracy improved from 0.83901 to 0.85555, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.8800 - loss: 0.4571 - val_accuracy: 0.8556 - val_loss: 0.4936 - learning_rate: 2.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8836 - loss: 0.4303\n",
      "Epoch 40: val_accuracy did not improve from 0.85555\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.8836 - loss: 0.4303 - val_accuracy: 0.8437 - val_loss: 0.5845 - learning_rate: 2.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8854 - loss: 0.4323\n",
      "Epoch 41: val_accuracy did not improve from 0.85555\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 171ms/step - accuracy: 0.8854 - loss: 0.4323 - val_accuracy: 0.8397 - val_loss: 0.5571 - learning_rate: 2.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8909 - loss: 0.4090\n",
      "Epoch 42: val_accuracy did not improve from 0.85555\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 176ms/step - accuracy: 0.8909 - loss: 0.4090 - val_accuracy: 0.8036 - val_loss: 0.6848 - learning_rate: 2.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8853 - loss: 0.4192\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.85555\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 178ms/step - accuracy: 0.8853 - loss: 0.4192 - val_accuracy: 0.8508 - val_loss: 0.5617 - learning_rate: 2.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8941 - loss: 0.3958\n",
      "Epoch 44: val_accuracy improved from 0.85555 to 0.85893, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 176ms/step - accuracy: 0.8941 - loss: 0.3957 - val_accuracy: 0.8589 - val_loss: 0.5085 - learning_rate: 8.0000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8974 - loss: 0.3621\n",
      "Epoch 45: val_accuracy improved from 0.85893 to 0.86095, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 176ms/step - accuracy: 0.8974 - loss: 0.3621 - val_accuracy: 0.8610 - val_loss: 0.5198 - learning_rate: 8.0000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.9008 - loss: 0.3578\n",
      "Epoch 46: val_accuracy did not improve from 0.86095\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 176ms/step - accuracy: 0.9008 - loss: 0.3578 - val_accuracy: 0.8512 - val_loss: 0.5385 - learning_rate: 8.0000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9063 - loss: 0.3451\n",
      "Epoch 47: val_accuracy improved from 0.86095 to 0.86399, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.9063 - loss: 0.3451 - val_accuracy: 0.8640 - val_loss: 0.5018 - learning_rate: 8.0000e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9068 - loss: 0.3492\n",
      "Epoch 48: val_accuracy did not improve from 0.86399\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.9068 - loss: 0.3492 - val_accuracy: 0.8606 - val_loss: 0.5030 - learning_rate: 8.0000e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9072 - loss: 0.3352\n",
      "Epoch 49: val_accuracy did not improve from 0.86399\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 178ms/step - accuracy: 0.9072 - loss: 0.3352 - val_accuracy: 0.8640 - val_loss: 0.4894 - learning_rate: 8.0000e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9084 - loss: 0.3448\n",
      "Epoch 50: val_accuracy did not improve from 0.86399\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 178ms/step - accuracy: 0.9084 - loss: 0.3448 - val_accuracy: 0.8532 - val_loss: 0.5185 - learning_rate: 8.0000e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9116 - loss: 0.3218\n",
      "Epoch 51: val_accuracy improved from 0.86399 to 0.86500, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 176ms/step - accuracy: 0.9116 - loss: 0.3218 - val_accuracy: 0.8650 - val_loss: 0.4784 - learning_rate: 8.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9140 - loss: 0.3178\n",
      "Epoch 52: val_accuracy did not improve from 0.86500\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 177ms/step - accuracy: 0.9139 - loss: 0.3178 - val_accuracy: 0.8593 - val_loss: 0.5015 - learning_rate: 8.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9101 - loss: 0.3350\n",
      "Epoch 53: val_accuracy improved from 0.86500 to 0.86568, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 174ms/step - accuracy: 0.9100 - loss: 0.3350 - val_accuracy: 0.8657 - val_loss: 0.4876 - learning_rate: 8.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9099 - loss: 0.3280\n",
      "Epoch 54: val_accuracy did not improve from 0.86568\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 170ms/step - accuracy: 0.9099 - loss: 0.3280 - val_accuracy: 0.8569 - val_loss: 0.5243 - learning_rate: 8.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9139 - loss: 0.3163\n",
      "Epoch 55: val_accuracy did not improve from 0.86568\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 178ms/step - accuracy: 0.9139 - loss: 0.3163 - val_accuracy: 0.8599 - val_loss: 0.5135 - learning_rate: 8.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9108 - loss: 0.3278\n",
      "Epoch 56: val_accuracy did not improve from 0.86568\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 179ms/step - accuracy: 0.9108 - loss: 0.3278 - val_accuracy: 0.8616 - val_loss: 0.5107 - learning_rate: 8.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9174 - loss: 0.3117\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.200000210199505e-05.\n",
      "\n",
      "Epoch 57: val_accuracy did not improve from 0.86568\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 178ms/step - accuracy: 0.9174 - loss: 0.3117 - val_accuracy: 0.8643 - val_loss: 0.5032 - learning_rate: 8.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9174 - loss: 0.2909\n",
      "Epoch 58: val_accuracy improved from 0.86568 to 0.86871, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 178ms/step - accuracy: 0.9174 - loss: 0.2909 - val_accuracy: 0.8687 - val_loss: 0.5011 - learning_rate: 3.2000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9175 - loss: 0.2855\n",
      "Epoch 59: val_accuracy did not improve from 0.86871\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 178ms/step - accuracy: 0.9175 - loss: 0.2855 - val_accuracy: 0.8684 - val_loss: 0.4969 - learning_rate: 3.2000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9176 - loss: 0.2980\n",
      "Epoch 60: val_accuracy did not improve from 0.86871\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 177ms/step - accuracy: 0.9176 - loss: 0.2980 - val_accuracy: 0.8684 - val_loss: 0.4986 - learning_rate: 3.2000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9170 - loss: 0.2951\n",
      "Epoch 61: val_accuracy did not improve from 0.86871\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 179ms/step - accuracy: 0.9170 - loss: 0.2950 - val_accuracy: 0.8674 - val_loss: 0.5048 - learning_rate: 3.2000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9141 - loss: 0.2930\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.280000142287463e-05.\n",
      "\n",
      "Epoch 62: val_accuracy did not improve from 0.86871\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 178ms/step - accuracy: 0.9141 - loss: 0.2930 - val_accuracy: 0.8677 - val_loss: 0.4954 - learning_rate: 3.2000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9262 - loss: 0.2617\n",
      "Epoch 63: val_accuracy improved from 0.86871 to 0.87006, saving model to saved_models/best_custom_cnn.keras\n",
      "\u001b[1m988/988\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 179ms/step - accuracy: 0.9262 - loss: 0.2617 - val_accuracy: 0.8701 - val_loss: 0.4922 - learning_rate: 1.2800e-05\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('saved_models/best_custom_cnn.keras',monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True, min_delta=0.001, verbose=1)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.4, patience=4, min_lr=1e-6, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stop, lr_reduce, checkpoint],\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15221d",
   "metadata": {},
   "source": [
    "## 9. Evaluate and Save\n",
    "\n",
    "Evaluate model on validation set and save final model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a2cc7b1-cb39-4cbb-97f8-1fcb3c4a64e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.8801 - loss: 0.4603\n",
      "Validation Accuracy: 0.87\n",
      "Model has been saved as custom_cnn_final.keras\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_generator)\n",
    "print(f'Validation Accuracy: {acc:.2f}')\n",
    "\n",
    "model.save('saved_models/custom_cnn_final.keras')\n",
    "print(\"Model has been saved as custom_cnn_final.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98051227",
   "metadata": {},
   "source": [
    "## 11. Classification Report\n",
    "Generate detailed classification report with precision, recall, and F1-score for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "439f406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery       0.91      0.90      0.91        48\n",
      "  biological       0.98      0.80      0.88        50\n",
      "   cardboard       0.86      0.80      0.83        92\n",
      "     clothes       0.96      0.92      0.94       267\n",
      "       glass       0.92      0.90      0.91       154\n",
      "       metal       0.77      0.84      0.80        51\n",
      "       paper       0.75      0.87      0.81        84\n",
      "     plastic       0.88      0.85      0.86       100\n",
      "       shoes       0.78      0.82      0.80        99\n",
      "       trash       0.78      0.94      0.85        48\n",
      "\n",
      "    accuracy                           0.87       993\n",
      "   macro avg       0.86      0.86      0.86       993\n",
      "weighted avg       0.88      0.87      0.88       993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_generator.reset()\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=list(test_generator.class_indices.keys())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf216",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
